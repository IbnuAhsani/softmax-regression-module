{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multinomial Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHSxa8uUdWjl",
        "colab_type": "text"
      },
      "source": [
        "[**The link for the tutorial**](https://www.youtube.com/watch?v=2JiXktBn_2M)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT-EXkNUXpfE",
        "colab_type": "code",
        "outputId": "67521005-ecc8-4447-e0f4-b17016a67cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZYK8aFUU5-2",
        "colab_type": "code",
        "outputId": "5f0d4efd-76d9-4fe6-b132-07f410e04646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMyzXzqdb_UQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(predictions, labels):\n",
        "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH-hKaf5iWUy",
        "colab_type": "text"
      },
      "source": [
        "**Example Program**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU6AoZLOVTbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "# mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiai8EMVfW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# graph = tf.Graph()\n",
        "# with graph.as_default():\n",
        "\n",
        "#   batch_size = 128\n",
        "#   beta = .001\n",
        "#   image_size = 28\n",
        "#   num_labels = 10\n",
        "\n",
        "#   tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
        "#   tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "#   tf_valid_dataset = tf.constant(mnist.validation.images)\n",
        "#   tf_test_dataset = tf.constant(mnist.test.images)\n",
        "\n",
        "#   w_logit = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
        "#   b_logit = tf.Variable(tf.zeros([num_labels]))\n",
        "\n",
        "#   def model(data):\n",
        "#     return tf.matmul(data, w_logit) + b_logit\n",
        "\n",
        "#   logits = model(tf_train_dataset)\n",
        "#   loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels))\n",
        "#   regularized_loss = tf.nn.l2_loss(w_logit) \n",
        "#   total_loss = loss + beta + regularized_loss\n",
        "\n",
        "#   optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(total_loss)\n",
        "\n",
        "#   train_prediction = tf.nn.softmax(logits)\n",
        "#   valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
        "#   test_prediction = tf.nn.softmax(model(tf_test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX6IYiohdeNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_step = 1001\n",
        "\n",
        "# with tf.Session(graph=graph) as session:\n",
        "#   tf.global_variables_initializer().run()\n",
        "#   print(\"initialized\")\n",
        "\n",
        "#   for step in range(num_step):\n",
        "#     batch_data, batch_labels = mnist.train.next_batch(batch_size=batch_size)\n",
        "#     feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "\n",
        "#     _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "\n",
        "#     if (step % 500 == 0):\n",
        "#       print(\"minibatch loss at step %d: %f\" % (step, l))\n",
        "#       print(\"minibatch accuracy: %.1f%%\" % get_accuracy(predictions, batch_labels))\n",
        "#       print(\"validation accuracy: %.1f%%\" % get_accuracy(valid_prediction.eval(), mnist.validation.labels))\n",
        "#       print(\"\\n\")\n",
        "  \n",
        "#   print(\"test accuracy: %.1f%%\" % get_accuracy(test_prediction.eval(), mnist.test.labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bYFar44ia4N",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIimC1Vqb2Zm",
        "colab_type": "code",
        "outputId": "1539ce83-3f7a-48eb-b0be-59ea056129e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_frame = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Content-Based Recommender System Data/Hypothesis Data/data-17-fv-tf-idf-scores-200.csv', header=None, sep=',')\n",
        "data_frame.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7556, 1562)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okaeWy0TUHZY",
        "colab_type": "code",
        "outputId": "278a279a-0b26-4f51-da15-54499fb3dfda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "header = []\n",
        "\n",
        "for i in range(len(data_frame.columns)-1):\n",
        "  header.append(str(i))\n",
        "\n",
        "header.append('target')\n",
        "\n",
        "data_frame.columns = header\n",
        "data_frame.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
              "       ...\n",
              "       '1552', '1553', '1554', '1555', '1556', '1557', '1558', '1559', '1560',\n",
              "       'target'],\n",
              "      dtype='object', length=1562)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV-VwBboY5x0",
        "colab_type": "code",
        "outputId": "56fee450-800e-457c-ff2d-4e6f41b566be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        }
      },
      "source": [
        "value_counts = data_frame['target'].value_counts()\n",
        "value_counts.plot(kind='bar')\n",
        "value_counts.rename_axis('journal_id').to_frame('counts')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>journal_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            counts\n",
              "journal_id        \n",
              "8             2645\n",
              "0              763\n",
              "1              754\n",
              "4              639\n",
              "2              599\n",
              "5              595\n",
              "3              536\n",
              "6              525\n",
              "7              500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHorK5xbV1dj",
        "colab_type": "code",
        "outputId": "43aa3efc-9042-418d-fa9f-97d559047908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "data_labels = data_frame['target']\n",
        "data_features = data_frame.drop('target',axis=1)\n",
        "\n",
        "near_miss = SMOTE()\n",
        "x_undersampled, y_undersampled = near_miss.fit_sample(data_features, data_labels)\n",
        "\n",
        "print(x_undersampled.shape)\n",
        "print(y_undersampled.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(23805, 1561)\n",
            "(23805,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVkxz906Xaw4",
        "colab_type": "code",
        "outputId": "13f8399a-e677-407a-a395-9e65f27abde8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "data_labels = data_frame['target']\n",
        "data_features = data_frame.drop('target',axis=1)\n",
        "\n",
        "near_miss = NearMiss(random_state=42)\n",
        "x_undersampled, y_undersampled = near_miss.fit_sample(data_features, data_labels)\n",
        "\n",
        "print(x_undersampled.shape)\n",
        "print(y_undersampled.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(4500, 1561)\n",
            "(4500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxljQuIlUAiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_labels = data_frame['target']\n",
        "# data_features = data_frame.drop('target',axis=1)\n",
        "\n",
        "# smk = SMOTETomek(random_state=42)\n",
        "# x_undersampled, y_undersampled = smk.fit_sample(data_features, data_labels)\n",
        "\n",
        "# print(x_undersampled.shape)\n",
        "# print(y_undersampled.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjaybCD6YGKq",
        "colab_type": "code",
        "outputId": "64c9249d-91ac-4e32-a147-b8c00970f091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "data_features_df = pd.DataFrame(data = x_undersampled[0:,0:], \n",
        "                                index = [i for i in range(x_undersampled.shape[0])],\n",
        "                                columns = [str(i) for i in range(x_undersampled.shape[1])])\n",
        "\n",
        "data_labels_df = pd.DataFrame(data = y_undersampled[0:], \n",
        "                                index = [i for i in range(y_undersampled.shape[0])],\n",
        "                                columns = ['target'])\n",
        "\n",
        "data_frame_undersampled = data_features_df.join(data_labels_df)\n",
        "\n",
        "print(data_features_df.head())\n",
        "print(data_labels_df.head())\n",
        "print(data_frame_undersampled.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2         3  ...  1557  1558  1559  1560\n",
            "0  4.602792  0.000000  0.306853  0.306853  ...   0.0   0.0   0.0   0.0\n",
            "1  0.000000  0.000000  0.306853  0.306853  ...   0.0   0.0   0.0   0.0\n",
            "2  1.227411  0.000000  0.306853  0.000000  ...   0.0   0.0   0.0   0.0\n",
            "3  0.920558  0.306853  0.000000  0.000000  ...   0.0   0.0   0.0   0.0\n",
            "4  1.841117  0.000000  0.306853  0.000000  ...   0.0   0.0   0.0   0.0\n",
            "\n",
            "[5 rows x 1561 columns]\n",
            "   target\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "          0         1         2         3  ...  1558  1559  1560  target\n",
            "0  4.602792  0.000000  0.306853  0.306853  ...   0.0   0.0   0.0       0\n",
            "1  0.000000  0.000000  0.306853  0.306853  ...   0.0   0.0   0.0       0\n",
            "2  1.227411  0.000000  0.306853  0.000000  ...   0.0   0.0   0.0       0\n",
            "3  0.920558  0.306853  0.000000  0.000000  ...   0.0   0.0   0.0       0\n",
            "4  1.841117  0.000000  0.306853  0.000000  ...   0.0   0.0   0.0       0\n",
            "\n",
            "[5 rows x 1562 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-hcK-vH6BCN",
        "colab_type": "code",
        "outputId": "389966a4-a0f4-47fc-a2cf-757a7378eac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        }
      },
      "source": [
        "value_counts_undersampled = data_labels_df['target'].value_counts()\n",
        "value_counts_undersampled.plot(kind='bar')\n",
        "value_counts_undersampled.rename_axis('journal_id').to_frame('counts')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>journal_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2645</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            counts\n",
              "journal_id        \n",
              "8             2645\n",
              "7             2645\n",
              "6             2645\n",
              "5             2645\n",
              "4             2645\n",
              "3             2645\n",
              "2             2645\n",
              "1             2645\n",
              "0             2645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tFsPI1hfxV4",
        "colab_type": "code",
        "outputId": "9a0623de-97a7-4844-9a88-c55ad1a555e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data_frame_shuffled_once = data_frame_undersampled.sample(frac=1)\n",
        "data_frame_shuffled_twice = data_frame_shuffled_once.sample(frac=1)\n",
        "data_frame_shuffled_twice.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1522</th>\n",
              "      <th>1523</th>\n",
              "      <th>1524</th>\n",
              "      <th>1525</th>\n",
              "      <th>1526</th>\n",
              "      <th>1527</th>\n",
              "      <th>1528</th>\n",
              "      <th>1529</th>\n",
              "      <th>1530</th>\n",
              "      <th>1531</th>\n",
              "      <th>1532</th>\n",
              "      <th>1533</th>\n",
              "      <th>1534</th>\n",
              "      <th>1535</th>\n",
              "      <th>1536</th>\n",
              "      <th>1537</th>\n",
              "      <th>1538</th>\n",
              "      <th>1539</th>\n",
              "      <th>1540</th>\n",
              "      <th>1541</th>\n",
              "      <th>1542</th>\n",
              "      <th>1543</th>\n",
              "      <th>1544</th>\n",
              "      <th>1545</th>\n",
              "      <th>1546</th>\n",
              "      <th>1547</th>\n",
              "      <th>1548</th>\n",
              "      <th>1549</th>\n",
              "      <th>1550</th>\n",
              "      <th>1551</th>\n",
              "      <th>1552</th>\n",
              "      <th>1553</th>\n",
              "      <th>1554</th>\n",
              "      <th>1555</th>\n",
              "      <th>1556</th>\n",
              "      <th>1557</th>\n",
              "      <th>1558</th>\n",
              "      <th>1559</th>\n",
              "      <th>1560</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19783</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.220058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.306853</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15354</th>\n",
              "      <td>3.146476</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.145632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.452484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.145632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161221</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1137</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306853</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.306853</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.613706</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17729</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157149</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.299407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.149703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6839</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.454823</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.920558</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1562 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0    1    2    3    4    5  ...  1556  1557  1558  1559  1560  target\n",
              "19783  0.000000  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0       6\n",
              "15354  3.146476  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0       3\n",
              "1137   0.000000  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0       1\n",
              "17729  0.000000  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0       5\n",
              "6839   0.000000  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   0.0   0.0       8\n",
              "\n",
              "[5 rows x 1562 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3BVaAVP-QdM",
        "colab_type": "text"
      },
      "source": [
        "**Program Train Test Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ea6mowM8tgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, data_test = train_test_split(data_frame_shuffled_twice, test_size = 0.2)\n",
        "\n",
        "data_train_features = data_train.drop('target',axis=1)\n",
        "data_train_labels = data_train['target']\n",
        "\n",
        "data_test_features = data_test.drop('target',axis=1)\n",
        "data_test_labels = data_test['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXXzi7ukh-AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "beta = .001\n",
        "learning_rate = 0.001\n",
        "num_epoch = 101\n",
        "num_features = 1561\n",
        "num_labels = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knarWmVqc3dw",
        "colab_type": "code",
        "outputId": "c4bed564-e123-4c31-e911-c7c76b471775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def to_onehot(y):\n",
        "  data = np.zeros((num_labels))\n",
        "  data[y] = 1\n",
        "  return data\n",
        "\n",
        "data_train_labels_one_hot_encoded = np.array([to_onehot(label) for label in data_train_labels])\n",
        "data_test_labels_one_hot_encoded = np.array([to_onehot(label) for label in data_test_labels])\n",
        "\n",
        "print(data_train_labels_one_hot_encoded.shape)\n",
        "print(data_test_labels_one_hot_encoded.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19044, 9)\n",
            "(4761, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkVv97Fs35YQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "  tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, num_features))\n",
        "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "  tf_test_dataset = tf.constant(data_test_features, dtype=tf.float32)\n",
        "\n",
        "  w_logit = tf.Variable(tf.truncated_normal([num_features, num_labels]))\n",
        "  b_logit = tf.Variable(tf.zeros([num_labels]))\n",
        "\n",
        "  def model(data):\n",
        "    return tf.matmul(data, w_logit) + b_logit\n",
        "\n",
        "  logits = model(tf_train_dataset)\n",
        "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels))\n",
        "  regularized_loss = tf.nn.l2_loss(w_logit) \n",
        "  total_loss = loss + beta + regularized_loss\n",
        "\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
        "\n",
        "  train_prediction = tf.nn.softmax(logits)\n",
        "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4UTYp95tqy",
        "colab_type": "code",
        "outputId": "5dac4d19-3ba2-4cc9-ca36-341db049fca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session(graph=graph) as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "  print(\"initialized\")\n",
        "\n",
        "  avg_batch_loss_list = []\n",
        "  batch_accuracy_list = []\n",
        "  total_batch = len(data_train_features)//batch_size\n",
        "  print(\"length of data train: %d\" % len(data_train_features))\n",
        "  print(\"total batch: %d\" % total_batch)\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "    \n",
        "    total_loss = 0\n",
        "\n",
        "    for i in range(0, (total_batch * batch_size), batch_size):\n",
        "      batch_index = range(i, i+1*batch_size)\n",
        "      batch_data = data_train_features[i:i+1*batch_size]\n",
        "      batch_labels = data_train_labels_one_hot_encoded[i:i+1*batch_size]\n",
        "\n",
        "      feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "      _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "\n",
        "      total_loss += l\n",
        "\n",
        "      if (i == (total_batch * batch_size) - batch_size):\n",
        "        batch_accuracy = get_accuracy(predictions, batch_labels)\n",
        "        batch_accuracy_list.append(batch_accuracy)\n",
        "\n",
        "        avg_batch_loss = total_loss / total_batch\n",
        "        avg_batch_loss_list.append(avg_batch_loss)\n",
        "        \n",
        "        print(\"epoch: %d\" % epoch)\n",
        "        print(\"minibatch loss: %f\" % avg_batch_loss)\n",
        "        print(\"minibatch accuracy: %.1f%%\" % batch_accuracy)\n",
        "        print(\"\\n\")\n",
        "\n",
        "  epochs_range = range(0, num_epoch)\n",
        "\n",
        "  plt.plot(epochs_range, avg_batch_loss_list, 'g', label='Training Loss')\n",
        "  plt.title('Training Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(epochs_range, batch_accuracy_list, 'b', label='Batch Accuracy')\n",
        "  plt.title('Batch Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"test accuracy: %.1f%%\" % get_accuracy(test_prediction.eval(), data_test_labels_one_hot_encoded))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialized\n",
            "length of data train: 19044\n",
            "total batch: 595\n",
            "epoch: 0\n",
            "minibatch loss: 4.655482\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 3.126366\n",
            "minibatch accuracy: 9.4%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.472378\n",
            "minibatch accuracy: 9.4%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.220194\n",
            "minibatch accuracy: 15.6%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.125378\n",
            "minibatch accuracy: 21.9%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.088016\n",
            "minibatch accuracy: 50.0%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.072122\n",
            "minibatch accuracy: 59.4%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.064824\n",
            "minibatch accuracy: 62.5%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.061251\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.059409\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.058416\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.057855\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.057520\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.057308\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.057162\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.057055\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.056971\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.056901\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.056841\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.056787\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.056740\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.056696\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.056657\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.056620\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.056587\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.056556\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.056528\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.056502\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.056477\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.056455\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.056434\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.056415\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.056397\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.056381\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.056365\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.056351\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.056338\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.056325\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.056314\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.056303\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.056293\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.056284\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.056275\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.056267\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.056259\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.056252\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.056245\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.056239\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.056233\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.056228\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.056223\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.056218\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.056213\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.056209\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.056205\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.056201\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.056198\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.056195\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.056192\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.056189\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.056186\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.056183\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.056181\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.056179\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.056177\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.056174\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.056173\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.056171\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.056169\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.056168\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.056166\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.056165\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.056163\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.056162\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.056161\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.056160\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.056159\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.056158\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.056157\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.056156\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.056155\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.056154\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.056153\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.056153\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.056152\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.056151\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.056151\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.056150\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.056150\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.056149\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.056149\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.056148\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.056148\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.056148\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.056147\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.056147\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.056147\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.056146\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.056146\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.056146\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.056145\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 80.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frRTs-debuMA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7MgIGcd23Nj",
        "colab_type": "text"
      },
      "source": [
        "**FAILED Program KFOLD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKJNAGRT3BGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "beta = .001\n",
        "learning_rate = 0.001\n",
        "num_epoch = 101\n",
        "num_features = 1561\n",
        "num_labels = 9\n",
        "num_k_splits = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrBXdAnk3D85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_onehot(y):\n",
        "  data = np.zeros((num_labels))\n",
        "  data[y] = 1\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrRcZALk3KQt",
        "colab_type": "code",
        "outputId": "80b3f36a-da07-46fc-e65e-51e393b1919f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = {}\n",
        "fold_counter = 1\n",
        "kfold = KFold(n_splits= num_k_splits, random_state=None, shuffle=True)\n",
        "\n",
        "for train_index, test_index in kfold.split(data_frame_shuffled_twice):\n",
        "\n",
        "  print(\"\\n==================================\")\n",
        "  print(\"Fold: %d\" % fold_counter)\n",
        "\n",
        "  k_fold_train_data = data_frame_shuffled_twice.loc[train_index, : ]\n",
        "  k_fold_train_features = k_fold_train_data.drop('target',axis=1).to_numpy()\n",
        "  k_fold_train_labels = k_fold_train_data['target']\n",
        "  k_fold_train_labels_one_hot_encoded = np.array([to_onehot(label) for label in k_fold_train_labels])\n",
        "\n",
        "  k_fold_test_data = data_frame_shuffled_twice.loc[test_index, : ]\n",
        "  k_fold_test_features = k_fold_test_data.drop('target',axis=1).to_numpy()\n",
        "  k_fold_test_labels = k_fold_test_data['target']\n",
        "  k_fold_test_labels_one_hot_encoded = np.array([to_onehot(label) for label in k_fold_test_labels])\n",
        "\n",
        "  reindexed_train_index = np.arange(len(train_index)) \n",
        "\n",
        "  graph = tf.Graph()\n",
        "\n",
        "  with graph.as_default():\n",
        "\n",
        "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, num_features))\n",
        "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "    tf_test_dataset = tf.constant(k_fold_test_features, dtype=tf.float32)\n",
        "\n",
        "    w_logit = tf.Variable(tf.truncated_normal([num_features, num_labels]))\n",
        "    b_logit = tf.Variable(tf.zeros([num_labels]))\n",
        "\n",
        "    def model(data):\n",
        "      return tf.matmul(data, w_logit) + b_logit\n",
        "\n",
        "    logits = model(tf_train_dataset)\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=tf_train_labels))\n",
        "    regularized_loss = tf.nn.l2_loss(w_logit) \n",
        "    total_loss = loss + beta + regularized_loss\n",
        "\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
        "\n",
        "    train_prediction = tf.nn.softmax(logits)\n",
        "    test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
        "\n",
        "  with tf.Session(graph=graph) as session:\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    avg_batch_loss_list = []\n",
        "    batch_accuracy_list = []\n",
        "    total_batch = len(train_index)//batch_size\n",
        "    \n",
        "    for epoch in range(num_epoch):\n",
        "\n",
        "      total_loss = 0\n",
        "\n",
        "      for i in range(0, (total_batch * batch_size), batch_size):\n",
        "\n",
        "        batch_index = reindexed_train_index[i : i+1*batch_size]\n",
        "        batch_features = k_fold_train_features[batch_index, : ]\n",
        "        batch_labels = k_fold_train_labels_one_hot_encoded[batch_index, : ]\n",
        "\n",
        "        feed_dict = {tf_train_dataset : batch_features, tf_train_labels : batch_labels}\n",
        "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "\n",
        "        total_loss += l\n",
        "\n",
        "      batch_accuracy = get_accuracy(predictions, batch_labels)\n",
        "      batch_accuracy_list.append(batch_accuracy)\n",
        "\n",
        "      avg_batch_loss = total_loss / total_batch\n",
        "      avg_batch_loss_list.append(avg_batch_loss)\n",
        "      \n",
        "      print(\"epoch: %d\" % epoch)\n",
        "      print(\"minibatch loss: %f\" % avg_batch_loss)\n",
        "      print(\"minibatch accuracy: %.1f%%\" % batch_accuracy)\n",
        "      print(\"\\n\")\n",
        "\n",
        "    test_accuracy = get_accuracy(test_prediction.eval(), k_fold_test_labels_one_hot_encoded)\n",
        "    \n",
        "    print(\"test accuracy: %.1f%%\" % test_accuracy)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  history_dict = {\n",
        "      \"batch_loss\": avg_batch_loss_list,\n",
        "      \"batch_accuracy\": batch_accuracy_list,\n",
        "      \"test_accuracy\": test_accuracy \n",
        "  }\n",
        "\n",
        "  history[str(fold_counter)] = history_dict\n",
        "  history_dict = {}\n",
        "  fold_counter += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053018\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.052969\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.052925\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.052884\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.052846\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.052812\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.052780\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.052751\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.052724\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.052700\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.052677\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.052656\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.052637\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.052619\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.052603\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.052588\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.052574\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.052561\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.052548\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.052537\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.052527\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.052517\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.052508\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.052500\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.052492\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.052485\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.052478\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.052472\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.052466\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.052461\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.052456\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.052451\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.052447\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.052443\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.052439\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.052435\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.052432\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.052429\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.052426\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.052423\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.052421\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.052418\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.052416\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.052414\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.052412\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.052410\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.052409\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.052407\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.052406\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.052404\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.052403\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.052402\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.052401\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.052400\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.052399\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.052398\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.052397\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.052396\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.052395\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.052394\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052394\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052393\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052393\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052392\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052391\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052391\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052391\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052390\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052390\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052389\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052389\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052389\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052388\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052388\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052388\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052387\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052387\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052387\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052387\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "test accuracy: 70.0%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 2\n",
            "epoch: 0\n",
            "minibatch loss: 3.950743\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.662098\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.216239\n",
            "minibatch accuracy: 12.5%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.090831\n",
            "minibatch accuracy: 21.9%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.060799\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.054700\n",
            "minibatch accuracy: 59.4%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.053868\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.053949\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.054063\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.054096\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.054070\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.054015\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.053949\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.053882\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.053818\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053758\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053704\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053655\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053610\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053571\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053535\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053502\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053473\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.053447\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.053423\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.053402\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.053383\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.053365\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.053349\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.053335\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.053322\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.053310\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.053300\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.053290\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.053281\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.053273\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.053266\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.053259\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.053253\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.053248\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.053242\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.053238\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.053233\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.053230\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.053226\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.053223\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.053220\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.053217\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.053214\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.053212\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.053209\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.053207\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.053206\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.053204\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.053202\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.053201\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.053199\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.053198\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.053197\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.053196\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.053195\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.053194\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.053193\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.053192\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.053191\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.053191\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.053190\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.053189\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.053189\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.053188\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.053188\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.053187\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.053187\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.053186\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.053186\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.053186\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.053185\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.053185\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.053185\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.053184\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.053184\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.053184\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.053184\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.053183\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.053183\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.053183\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.053183\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.053183\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.053181\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.053181\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.053181\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "test accuracy: 72.5%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 3\n",
            "epoch: 0\n",
            "minibatch loss: 3.738111\n",
            "minibatch accuracy: 18.8%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.566970\n",
            "minibatch accuracy: 18.8%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.169253\n",
            "minibatch accuracy: 21.9%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.066849\n",
            "minibatch accuracy: 28.1%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.048705\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.048577\n",
            "minibatch accuracy: 37.5%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.050662\n",
            "minibatch accuracy: 43.8%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.052162\n",
            "minibatch accuracy: 46.9%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.052977\n",
            "minibatch accuracy: 50.0%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.053368\n",
            "minibatch accuracy: 50.0%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.053537\n",
            "minibatch accuracy: 53.1%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.053596\n",
            "minibatch accuracy: 56.2%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.053605\n",
            "minibatch accuracy: 56.2%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.053592\n",
            "minibatch accuracy: 62.5%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.053570\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053546\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053523\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053502\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053482\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053465\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053450\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053437\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053426\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.053416\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.053407\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.053400\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.053393\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.053387\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.053382\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.053378\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.053374\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.053371\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.053368\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.053366\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.053364\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.053362\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.053361\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.053359\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.053358\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.053357\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.053357\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.053356\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.053353\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.053354\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.053355\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "test accuracy: 74.6%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 4\n",
            "epoch: 0\n",
            "minibatch loss: 4.262888\n",
            "minibatch accuracy: 18.8%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.828333\n",
            "minibatch accuracy: 15.6%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.302282\n",
            "minibatch accuracy: 15.6%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.134766\n",
            "minibatch accuracy: 12.5%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.083210\n",
            "minibatch accuracy: 12.5%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.066219\n",
            "minibatch accuracy: 18.8%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.059898\n",
            "minibatch accuracy: 15.6%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.057210\n",
            "minibatch accuracy: 21.9%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.055917\n",
            "minibatch accuracy: 21.9%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.055224\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.054811\n",
            "minibatch accuracy: 34.4%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.054539\n",
            "minibatch accuracy: 34.4%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.054343\n",
            "minibatch accuracy: 34.4%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.054189\n",
            "minibatch accuracy: 37.5%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.054062\n",
            "minibatch accuracy: 40.6%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053954\n",
            "minibatch accuracy: 46.9%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053858\n",
            "minibatch accuracy: 46.9%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053773\n",
            "minibatch accuracy: 50.0%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053696\n",
            "minibatch accuracy: 50.0%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053627\n",
            "minibatch accuracy: 50.0%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053565\n",
            "minibatch accuracy: 53.1%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053508\n",
            "minibatch accuracy: 53.1%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053456\n",
            "minibatch accuracy: 53.1%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.053409\n",
            "minibatch accuracy: 56.2%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.053366\n",
            "minibatch accuracy: 59.4%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.053326\n",
            "minibatch accuracy: 62.5%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.053290\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.053257\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.053227\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.053200\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.053174\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.053151\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.053129\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.053110\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.053092\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.053075\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.053059\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.053045\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.053032\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.053020\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.053009\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.052998\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.052989\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.052980\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.052971\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.052964\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.052956\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.052950\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.052944\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.052938\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.052933\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.052928\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.052923\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.052919\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.052915\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.052911\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.052907\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.052904\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.052901\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.052898\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.052896\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.052893\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.052891\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.052889\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.052887\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.052885\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.052883\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.052881\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.052880\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.052879\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.052877\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.052876\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.052875\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.052874\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.052873\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.052872\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.052871\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.052870\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.052869\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.052868\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.052868\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.052867\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052866\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052866\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052865\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052865\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052864\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052864\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052863\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052863\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052863\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052862\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052862\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052862\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052861\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052861\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052861\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052861\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052860\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052860\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052860\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "test accuracy: 67.5%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 5\n",
            "epoch: 0\n",
            "minibatch loss: 4.135669\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.768400\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.270696\n",
            "minibatch accuracy: 37.5%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.116508\n",
            "minibatch accuracy: 40.6%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.072574\n",
            "minibatch accuracy: 56.2%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.059964\n",
            "minibatch accuracy: 56.2%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.056074\n",
            "minibatch accuracy: 62.5%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.054717\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.054155\n",
            "minibatch accuracy: 75.0%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.053872\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.053701\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.053580\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.053486\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.053408\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.053341\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053282\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053230\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053183\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053141\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053103\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053069\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053038\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053010\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.052985\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.052962\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.052942\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.052923\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.052906\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.052890\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.052876\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.052863\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.052852\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.052841\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.052831\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.052822\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.052814\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.052806\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.052799\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.052793\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.052787\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.052782\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.052777\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.052772\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.052768\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.052764\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.052761\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.052757\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.052754\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.052751\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.052749\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.052746\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.052744\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.052742\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.052740\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.052738\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.052737\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.052735\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.052734\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.052732\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.052731\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.052730\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.052729\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.052728\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.052727\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.052726\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.052725\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.052724\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.052723\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.052723\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.052722\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.052722\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.052721\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.052720\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.052720\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.052720\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.052719\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.052719\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.052718\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.052718\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.052718\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.052717\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.052717\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052717\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052717\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052716\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052716\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052716\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052716\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052716\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052715\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052714\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052714\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052714\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052714\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052714\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "test accuracy: 69.6%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 6\n",
            "epoch: 0\n",
            "minibatch loss: 4.003421\n",
            "minibatch accuracy: 0.0%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.688381\n",
            "minibatch accuracy: 0.0%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.225422\n",
            "minibatch accuracy: 3.1%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.093350\n",
            "minibatch accuracy: 9.4%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.061439\n",
            "minibatch accuracy: 37.5%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.054886\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.053935\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.053967\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.054053\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.054066\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.054027\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.053963\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.053891\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.053818\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.053749\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053685\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053626\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053572\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053523\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053479\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053438\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053401\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053367\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.053336\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.053308\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.053282\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.053259\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.053237\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.053217\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.053199\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.053182\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.053167\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.053152\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.053139\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.053127\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.053116\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.053106\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.053096\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.053088\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.053079\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.053072\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.053065\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.053058\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.053053\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.053047\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.053042\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.053037\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.053033\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.053028\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.053025\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.053021\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.053018\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.053014\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.053012\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.053009\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.053006\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.053004\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.053002\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.053000\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.052998\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.052996\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.052994\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.052993\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.052991\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.052990\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.052989\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.052988\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.052986\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.052985\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.052984\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.052983\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.052983\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.052982\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.052981\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.052980\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.052980\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.052979\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.052978\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.052978\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.052977\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.052977\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.052977\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052976\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052976\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052975\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052975\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052975\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052974\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052974\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052974\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052974\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052973\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052973\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052973\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052973\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052973\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052972\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052972\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052972\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052972\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052972\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "test accuracy: 74.7%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 7\n",
            "epoch: 0\n",
            "minibatch loss: 4.092606\n",
            "minibatch accuracy: 0.0%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.752772\n",
            "minibatch accuracy: 0.0%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.268402\n",
            "minibatch accuracy: 3.1%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.117929\n",
            "minibatch accuracy: 15.6%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.073862\n",
            "minibatch accuracy: 37.5%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.060481\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.055968\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.054213\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.053422\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.053017\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.052787\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.052643\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.052544\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.052472\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.052415\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.052368\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.052328\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.052294\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.052264\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.052237\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.052214\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.052193\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.052175\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.052158\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.052143\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.052130\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.052118\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.052108\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.052098\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.052090\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.052082\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.052075\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.052069\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.052064\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.052059\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.052054\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.052050\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.052046\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.052043\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.052040\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.052037\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.052035\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.052032\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.052030\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.052028\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.052027\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.052025\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.052024\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.052022\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.052021\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.052020\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.052019\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.052018\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.052017\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.052016\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.052015\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.052015\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.052014\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.052014\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.052013\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.052013\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.052012\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.052012\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.052011\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.052011\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.052011\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.052010\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.052010\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.052010\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.052009\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.052009\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.052009\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.052009\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.052009\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.052008\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.052008\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.052008\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.052008\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.052008\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.052008\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052007\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "test accuracy: 68.0%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 8\n",
            "epoch: 0\n",
            "minibatch loss: 3.826146\n",
            "minibatch accuracy: 12.5%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.614927\n",
            "minibatch accuracy: 15.6%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.197697\n",
            "minibatch accuracy: 25.0%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.082675\n",
            "minibatch accuracy: 34.4%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.057038\n",
            "minibatch accuracy: 59.4%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.053109\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.053376\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.053991\n",
            "minibatch accuracy: 81.2%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.054340\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.054456\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.054437\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.054352\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.054241\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.054122\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.054006\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053896\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053794\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053700\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053613\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053534\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053461\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053395\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053334\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.053278\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.053226\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.053179\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.053136\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.053096\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.053059\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.053025\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.052993\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.052964\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.052937\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.052913\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.052890\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.052868\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.052849\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.052830\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.052813\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.052798\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.052783\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.052770\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.052757\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.052745\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.052734\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.052724\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.052714\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.052706\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.052697\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.052690\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.052682\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.052676\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.052670\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.052664\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.052658\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.052653\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.052648\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.052644\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.052640\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.052636\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.052632\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.052629\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.052626\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.052623\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.052620\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.052617\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.052615\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.052613\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.052610\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.052608\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.052607\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.052605\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.052603\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.052602\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.052600\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.052599\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.052598\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.052596\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.052595\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.052594\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.052593\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.052592\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052591\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052591\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052590\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052589\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052589\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052588\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052587\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052587\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052586\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052586\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052585\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052585\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052585\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052584\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052584\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052583\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052583\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052583\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052583\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "test accuracy: 72.7%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 9\n",
            "epoch: 0\n",
            "minibatch loss: 4.000509\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.698495\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.235349\n",
            "minibatch accuracy: 9.4%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.099120\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.064050\n",
            "minibatch accuracy: 56.2%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.055872\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.054235\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.054023\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.054039\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.054045\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.054015\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.053961\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.053897\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.053831\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.053766\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.053704\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.053647\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.053595\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.053546\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.053502\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.053462\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.053426\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.053392\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.053361\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.053333\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.053308\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.053284\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.053262\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.053243\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.053224\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.053207\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.053192\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.053178\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.053165\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.053153\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.053141\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.053131\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.053121\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.053113\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.053104\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.053097\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.053090\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.053083\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.053077\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.053072\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.053066\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.053061\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.053057\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.053053\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.053049\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.053045\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.053042\n",
            "minibatch accuracy: 100.0%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.053039\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.053036\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.053033\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.053030\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.053028\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.053026\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.053024\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.053022\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.053020\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.053018\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.053016\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.053015\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.053014\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.053012\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.053011\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.053010\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.053009\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.053008\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.053007\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.053006\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.053005\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.053004\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.053004\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.053003\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.053002\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.053002\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.053001\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.053001\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.053000\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.053000\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.052999\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.052999\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.052999\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.052998\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.052998\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.052998\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.052997\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.052997\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.052997\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.052997\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.052996\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.052996\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.052996\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.052996\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.052996\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.052995\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.052995\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.052995\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.052995\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "test accuracy: 71.6%\n",
            "\n",
            "\n",
            "\n",
            "==================================\n",
            "Fold: 10\n",
            "epoch: 0\n",
            "minibatch loss: 4.193601\n",
            "minibatch accuracy: 9.4%\n",
            "\n",
            "\n",
            "epoch: 1\n",
            "minibatch loss: 2.788077\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 2\n",
            "minibatch loss: 2.280007\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 3\n",
            "minibatch loss: 2.123327\n",
            "minibatch accuracy: 6.2%\n",
            "\n",
            "\n",
            "epoch: 4\n",
            "minibatch loss: 2.077629\n",
            "minibatch accuracy: 9.4%\n",
            "\n",
            "\n",
            "epoch: 5\n",
            "minibatch loss: 2.063689\n",
            "minibatch accuracy: 12.5%\n",
            "\n",
            "\n",
            "epoch: 6\n",
            "minibatch loss: 2.058953\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 7\n",
            "minibatch loss: 2.057089\n",
            "minibatch accuracy: 31.2%\n",
            "\n",
            "\n",
            "epoch: 8\n",
            "minibatch loss: 2.056223\n",
            "minibatch accuracy: 34.4%\n",
            "\n",
            "\n",
            "epoch: 9\n",
            "minibatch loss: 2.055749\n",
            "minibatch accuracy: 40.6%\n",
            "\n",
            "\n",
            "epoch: 10\n",
            "minibatch loss: 2.055449\n",
            "minibatch accuracy: 53.1%\n",
            "\n",
            "\n",
            "epoch: 11\n",
            "minibatch loss: 2.055235\n",
            "minibatch accuracy: 59.4%\n",
            "\n",
            "\n",
            "epoch: 12\n",
            "minibatch loss: 2.055069\n",
            "minibatch accuracy: 62.5%\n",
            "\n",
            "\n",
            "epoch: 13\n",
            "minibatch loss: 2.054933\n",
            "minibatch accuracy: 62.5%\n",
            "\n",
            "\n",
            "epoch: 14\n",
            "minibatch loss: 2.054816\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 15\n",
            "minibatch loss: 2.054713\n",
            "minibatch accuracy: 65.6%\n",
            "\n",
            "\n",
            "epoch: 16\n",
            "minibatch loss: 2.054623\n",
            "minibatch accuracy: 68.8%\n",
            "\n",
            "\n",
            "epoch: 17\n",
            "minibatch loss: 2.054542\n",
            "minibatch accuracy: 71.9%\n",
            "\n",
            "\n",
            "epoch: 18\n",
            "minibatch loss: 2.054469\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 19\n",
            "minibatch loss: 2.054403\n",
            "minibatch accuracy: 78.1%\n",
            "\n",
            "\n",
            "epoch: 20\n",
            "minibatch loss: 2.054344\n",
            "minibatch accuracy: 84.4%\n",
            "\n",
            "\n",
            "epoch: 21\n",
            "minibatch loss: 2.054290\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 22\n",
            "minibatch loss: 2.054241\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 23\n",
            "minibatch loss: 2.054197\n",
            "minibatch accuracy: 87.5%\n",
            "\n",
            "\n",
            "epoch: 24\n",
            "minibatch loss: 2.054157\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 25\n",
            "minibatch loss: 2.054121\n",
            "minibatch accuracy: 90.6%\n",
            "\n",
            "\n",
            "epoch: 26\n",
            "minibatch loss: 2.054088\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 27\n",
            "minibatch loss: 2.054058\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 28\n",
            "minibatch loss: 2.054031\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 29\n",
            "minibatch loss: 2.054006\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 30\n",
            "minibatch loss: 2.053983\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 31\n",
            "minibatch loss: 2.053962\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 32\n",
            "minibatch loss: 2.053943\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 33\n",
            "minibatch loss: 2.053925\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 34\n",
            "minibatch loss: 2.053909\n",
            "minibatch accuracy: 93.8%\n",
            "\n",
            "\n",
            "epoch: 35\n",
            "minibatch loss: 2.053894\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 36\n",
            "minibatch loss: 2.053881\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 37\n",
            "minibatch loss: 2.053868\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 38\n",
            "minibatch loss: 2.053857\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 39\n",
            "minibatch loss: 2.053846\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 40\n",
            "minibatch loss: 2.053837\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 41\n",
            "minibatch loss: 2.053828\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 42\n",
            "minibatch loss: 2.053819\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 43\n",
            "minibatch loss: 2.053812\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 44\n",
            "minibatch loss: 2.053805\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 45\n",
            "minibatch loss: 2.053798\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 46\n",
            "minibatch loss: 2.053792\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 47\n",
            "minibatch loss: 2.053787\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 48\n",
            "minibatch loss: 2.053781\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 49\n",
            "minibatch loss: 2.053777\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 50\n",
            "minibatch loss: 2.053772\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 51\n",
            "minibatch loss: 2.053768\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 52\n",
            "minibatch loss: 2.053764\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 53\n",
            "minibatch loss: 2.053760\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 54\n",
            "minibatch loss: 2.053757\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 55\n",
            "minibatch loss: 2.053754\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 56\n",
            "minibatch loss: 2.053751\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 57\n",
            "minibatch loss: 2.053748\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 58\n",
            "minibatch loss: 2.053746\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 59\n",
            "minibatch loss: 2.053744\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 60\n",
            "minibatch loss: 2.053741\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 61\n",
            "minibatch loss: 2.053739\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 62\n",
            "minibatch loss: 2.053738\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 63\n",
            "minibatch loss: 2.053736\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 64\n",
            "minibatch loss: 2.053734\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 65\n",
            "minibatch loss: 2.053733\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 66\n",
            "minibatch loss: 2.053731\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 67\n",
            "minibatch loss: 2.053730\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 68\n",
            "minibatch loss: 2.053729\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 69\n",
            "minibatch loss: 2.053727\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 70\n",
            "minibatch loss: 2.053726\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 71\n",
            "minibatch loss: 2.053725\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 72\n",
            "minibatch loss: 2.053724\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 73\n",
            "minibatch loss: 2.053723\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 74\n",
            "minibatch loss: 2.053723\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 75\n",
            "minibatch loss: 2.053722\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 76\n",
            "minibatch loss: 2.053721\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 77\n",
            "minibatch loss: 2.053720\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 78\n",
            "minibatch loss: 2.053720\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 79\n",
            "minibatch loss: 2.053719\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 80\n",
            "minibatch loss: 2.053719\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 81\n",
            "minibatch loss: 2.053718\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 82\n",
            "minibatch loss: 2.053717\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 83\n",
            "minibatch loss: 2.053717\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 84\n",
            "minibatch loss: 2.053717\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 85\n",
            "minibatch loss: 2.053716\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 86\n",
            "minibatch loss: 2.053716\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 87\n",
            "minibatch loss: 2.053715\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 88\n",
            "minibatch loss: 2.053715\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 89\n",
            "minibatch loss: 2.053715\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 90\n",
            "minibatch loss: 2.053715\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 91\n",
            "minibatch loss: 2.053714\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 92\n",
            "minibatch loss: 2.053714\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 93\n",
            "minibatch loss: 2.053714\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 94\n",
            "minibatch loss: 2.053713\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 95\n",
            "minibatch loss: 2.053713\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 96\n",
            "minibatch loss: 2.053713\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 97\n",
            "minibatch loss: 2.053713\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 98\n",
            "minibatch loss: 2.053713\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 99\n",
            "minibatch loss: 2.053713\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "epoch: 100\n",
            "minibatch loss: 2.053712\n",
            "minibatch accuracy: 96.9%\n",
            "\n",
            "\n",
            "test accuracy: 70.6%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBfPObWr-TH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in history:\n",
        "  print(\"\\n==================================\")\n",
        "  print(\"Epoch: %s\" % epoch)\n",
        "\n",
        "  history_batch_loss = history[epoch]['batch_loss']\n",
        "  history_batch_accuracy = history[epoch]['batch_accuracy']\n",
        "  history_test_accuracy = history[epoch]['test_accuracy']\n",
        "\n",
        "  epochs_range = range(0, num_epoch)\n",
        "\n",
        "  plt.plot(epochs_range, history_batch_loss, 'g', label='Training Loss')\n",
        "  plt.title('Training Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(epochs_range, history_batch_accuracy, 'b', label='Batch Accuracy')\n",
        "  plt.title('Batch Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Test Accuracy: %.1f%%\" % history_test_accuracy)\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}